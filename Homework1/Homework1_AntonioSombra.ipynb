{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation, BatchNormalization, regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF YOU DOWNLOADED THE DATA .zip , uncomment and run:\n",
    "\n",
    "# !pip install pyunpack\n",
    "# from pyunpack import Archive\n",
    "# Archive('./data.zip').extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading /  Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"./data\"\n",
    "train_data_path = \"./data/uc_train_256_data\"\n",
    "test_data_path =\"./data/uc_test_256\"\n",
    "\n",
    "train_image_paths = sorted(glob.glob(train_data_path + \"/*.*\"))\n",
    "test_image_paths = sorted(glob.glob(test_data_path + \"/*.*\"))\n",
    "\n",
    "#Partition with image paths\n",
    "partition = {}\n",
    "partition['train'] = train_image_paths\n",
    "partition['validation'] = test_image_paths\n",
    "               \n",
    "#complete list of 21 labels' names\n",
    "lista_labels = [\n",
    "'agricultural',\n",
    "'airplane',\n",
    "'baseballdiamond',\n",
    "'beach',\n",
    "'buildings',\n",
    "'chaparral',\n",
    "'denseresidential',\n",
    "'forest',\n",
    "'freeway',\n",
    "'golfcourse',\n",
    "'harbor',\n",
    "'intersection',\n",
    "'mediumresidential',\n",
    "'mobilehomepark',\n",
    "'overpass',\n",
    "'parkinglot',\n",
    "'river',\n",
    "'runway',\n",
    "'sparseresidential',\n",
    "'storagetanks',\n",
    "'tenniscourt'\n",
    "]\n",
    "\n",
    "#Dict for labels, ex: label_dict[path] = 'agricutural'\n",
    "label_dict = {}\n",
    "for path in train_image_paths:\n",
    "    for i in range(len(lista_labels)):\n",
    "        if lista_labels[i] in path:\n",
    "            label_dict[path] = lista_labels[i]\n",
    "for path in test_image_paths:\n",
    "    for i in range(len(lista_labels)):\n",
    "        if lista_labels[i] in path:\n",
    "             label_dict[path] = lista_labels[i]\n",
    "\n",
    "\n",
    "#Dict for integer class encoding and vice versa, ex: 'agricultural' = 0, 'airplane' = 1\n",
    "\n",
    "dict_indx_to_labels = {v:k for v, k in enumerate(lista_labels)} \n",
    "dict_labels_to_indx = {k:v for v, k in enumerate(lista_labels)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "def Scaling(image):\n",
    "    return np.array(image) / 255.0\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_paths, labels, batch_size=32, dim=(256,256), n_channels=3,\n",
    "                 n_classes=21, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_paths = list_paths\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of paths\n",
    "        list_paths_temp = [self.list_paths[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_paths_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_paths_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, path in enumerate(list_paths_temp):\n",
    "            with open(path, 'rb') as img_path:                              \n",
    "                image_PIL = Image.open(io.BytesIO(img_path.read()))\n",
    "                np_image_scaled = Scaling(image_PIL)\n",
    "                X[i,] = np_image_scaled#.transpose(2,0,1) #channels first\n",
    "            # Store class\n",
    "            y[i] = dict_labels_to_indx[self.labels[path]]\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for debug:\n",
    "# dataset = DataGenerator(partition['train'], label_dict)\n",
    "# X, y = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(droprate=0.25, img_rows=256, img_cols=256):\n",
    "    # input image dimensions\n",
    "    droprate=droprate\n",
    "    input_shape = (img_rows, img_cols, 3) #RGB\n",
    "\n",
    "    #Start Neural Network\n",
    "    model = Sequential()\n",
    "    #convolution 1st layer\n",
    "    model.add(Conv2D(128, kernel_size=(7, 7), padding=\"same\",\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    #convolution 2nd layer\n",
    "    model.add(Conv2D(256, kernel_size=(5, 5), activation='relu',padding=\"same\"))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    #convolution 3rd layer\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu',padding=\"same\"))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    #convolution 4th layer\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding=\"same\"))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    #convolution 5th layer\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding=\"same\"))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    #Fully connected 1st layer\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(256,use_bias=False)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(droprate))      \n",
    "\n",
    "    #Fully connected final layer\n",
    "    model.add(Dense(21)) #8\n",
    "    model.add(Activation('softmax')) #9\n",
    "\n",
    "      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 128)     18944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256, 256, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 256)     819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 21)                5397      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 21)                0         \n",
      "=================================================================\n",
      "Total params: 5,602,197\n",
      "Trainable params: 5,599,125\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "840/840 [==============================] - 163s 194ms/step - loss: 1.8978 - acc: 0.4238 - val_loss: 2.2014 - val_acc: 0.3726\n",
      "Epoch 2/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 1.0566 - acc: 0.6600 - val_loss: 1.8154 - val_acc: 0.4760\n",
      "Epoch 3/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.7060 - acc: 0.7719 - val_loss: 1.2893 - val_acc: 0.6370\n",
      "Epoch 4/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.5163 - acc: 0.8318 - val_loss: 0.6394 - val_acc: 0.7740\n",
      "Epoch 5/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.4475 - acc: 0.8539 - val_loss: 0.4813 - val_acc: 0.8365\n",
      "Epoch 6/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.3452 - acc: 0.8866 - val_loss: 0.8004 - val_acc: 0.7572\n",
      "Epoch 7/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.2993 - acc: 0.9051 - val_loss: 0.4793 - val_acc: 0.8486\n",
      "Epoch 8/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.2337 - acc: 0.9243 - val_loss: 0.9244 - val_acc: 0.7356\n",
      "Epoch 9/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.2205 - acc: 0.9263 - val_loss: 0.3335 - val_acc: 0.8846\n",
      "Epoch 10/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.2068 - acc: 0.9318 - val_loss: 0.3132 - val_acc: 0.9159\n",
      "Epoch 11/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.1729 - acc: 0.9443 - val_loss: 0.3571 - val_acc: 0.8990\n",
      "Epoch 12/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.1624 - acc: 0.9490 - val_loss: 0.4501 - val_acc: 0.8678\n",
      "Epoch 13/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.1645 - acc: 0.9488 - val_loss: 0.4649 - val_acc: 0.8630\n",
      "Epoch 14/50\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 0.1309 - acc: 0.9567 - val_loss: 0.2094 - val_acc: 0.9447\n",
      "Epoch 15/50\n",
      "148/840 [====>.........................] - ETA: 2:09 - loss: 0.1175 - acc: 0.9637"
     ]
    }
   ],
   "source": [
    "# Generator parameters\n",
    "params = {'dim': (256,256),\n",
    "          'batch_size': 8,\n",
    "          'n_classes': 21,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "DATAPATH = \"./data\"\n",
    "train_data_path = \"./data/uc_train_256_data\"\n",
    "test_data_path =\"./data/uc_test_256\"\n",
    "\n",
    "train_image_paths = sorted(glob.glob(train_data_path + \"/*.*\"))\n",
    "test_image_paths = sorted(glob.glob(test_data_path + \"/*.*\"))\n",
    "\n",
    "partition = {}\n",
    "partition['train'] = train_image_paths\n",
    "partition['validation'] = test_image_paths\n",
    "partition = partition\n",
    "labels = label_dict\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Training parameters\n",
    "epochs = 50\n",
    "droprate=0.25\n",
    "lr = 0.001\n",
    "\n",
    "# Design model\n",
    "model = CNN(droprate)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "#keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model_path = './best_model.pth'\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_acc', \n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=1),\n",
    "    ModelCheckpoint(model_path,\n",
    "        monitor='val_acc', \n",
    "        save_best_only=True, \n",
    "        mode='max',\n",
    "        verbose=0)\n",
    "]\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks = callbacks,\n",
    "                    epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Since I used the validation dataset for test I don't need this for now\n",
    "\n",
    "# test_images = []\n",
    "# for idx, filename in enumerate(test_image_paths):\n",
    "#     with open(filename, 'rb') as img:                              \n",
    "#             img = Image.open(io.BytesIO(img.read()))\n",
    "#             test_images.append(img) \n",
    "# test_set = np.array([Scaling(test_images[i]) for i in range(len(test_images))])\n",
    "# X_test_CNN = test_set\n",
    "\n",
    "# y_test_CNN = to_categorical([dict_labels_to_indx[label_dict[path]] for path in test_image_paths])\n",
    "\n",
    "# score = model.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "\n",
    "# #print loss and accuracy\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
